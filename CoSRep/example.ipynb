{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4461a6d",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a46218df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from utils_ae import (SCDataset, dense_and_unique, evaluate, normalization_pro, normalization_rna,setup_seed)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 256 \n",
    "        self.test_batch_size = 256\n",
    "        self.epochs = 30 \n",
    "        self.lr = 1e-3\n",
    "        self.no_cuda = True\n",
    "        self.seed = 1105\n",
    "        self.repeat = 1\n",
    "        self.frac_finetune_test = 0.1\n",
    "        self.resume = False\n",
    "        self.RNA_path = '/dataset/mBrain/adata_RNA.h5ad'\n",
    "        self.Pro_path = '/dataset/mBrain/adata_ADT.h5ad'\n",
    "        self.method_flag = 'CoSRep'\n",
    "        self.shared_dim_rna = 128 \n",
    "        self.specific_dim_rna = 128 \n",
    "        self.shared_dim_pro = 128 \n",
    "        self.specific_dim_pro = 128 \n",
    "        self.num_hidden_pro = 128 \n",
    "        self.num_hidden_rna = 512   \n",
    "        self.dropout = 0.25  \n",
    "        self.dim_rna = None\n",
    "        self.dim_pro = None\n",
    "\n",
    "args = Args()\n",
    "setup_seed(args.seed+args.repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89ce850",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bdb2ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of origin RNA genes:  19848\n",
      "Total number of origin proteins:  34\n",
      "Total number of origin cells:  13052\n",
      "# of NAN in X 0\n",
      "# of NAN in X 0\n"
     ]
    }
   ],
   "source": [
    "#---- Load Single Cell Data ----#\n",
    "# Load single-cell RNA and protein data from specified paths\n",
    "script_directory = os.getcwd()\n",
    "base_path = os.path.abspath(os.path.join(script_directory, '../'))\n",
    "scRNA_adata = sc.read_h5ad(base_path + args.RNA_path)\n",
    "scP_adata = sc.read_h5ad(base_path + args.Pro_path)\n",
    "\n",
    "#---- Convert to Dense Matrix ----#\n",
    "# Ensure data is in dense format and has unique indices\n",
    "scP_adata = dense_and_unique(scP_adata)\n",
    "scRNA_adata = dense_and_unique(scRNA_adata)\n",
    "\n",
    "# Print basic information about the original data\n",
    "print('Total number of origin RNA genes: ', scRNA_adata.n_vars)\n",
    "print('Total number of origin proteins: ', scP_adata.n_vars)\n",
    "print('Total number of origin cells: ', scRNA_adata.n_obs)\n",
    "print('# of NAN in X', np.isnan(scRNA_adata.X).sum())\n",
    "print('# of NAN in X', np.isnan(scP_adata.X).sum())\n",
    "\n",
    "#--- Separate Training and Testing Set ---\n",
    "# Split data into training, validation, and testing sets\n",
    "train_val_index, test_index = train_test_split(\n",
    "    scRNA_adata.obs.index, \n",
    "    test_size=0.1, \n",
    "    random_state=args.seed + args.repeat\n",
    ")\n",
    "# Second split: Take 10% of the remaining 90% as validation set (effectively 9% of the original data)\n",
    "train_index, val_index = train_test_split(\n",
    "    train_val_index, \n",
    "    test_size=0.1111,  \n",
    "    random_state=args.seed + args.repeat\n",
    ")\n",
    "\n",
    "# Assign data subsets based on indices\n",
    "train_rna = scRNA_adata[train_index]\n",
    "test_rna = scRNA_adata[test_index]\n",
    "train_protein = scP_adata[train_index]\n",
    "test_protein = scP_adata[test_index]\n",
    "val_rna = scRNA_adata[val_index]\n",
    "val_protein = scP_adata[val_index]\n",
    "\n",
    "#---- Normalization ----#\n",
    "# Normalize RNA and protein data for training, testing, and validation sets\n",
    "train_rna = normalization_rna(train_rna)\n",
    "train_protein = normalization_pro(train_protein)\n",
    "test_rna = normalization_rna(test_rna)\n",
    "test_protein = normalization_pro(test_protein)\n",
    "val_rna = normalization_rna(val_rna)\n",
    "val_protein = normalization_pro(val_protein)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e850724",
   "metadata": {},
   "source": [
    "### Build dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "225175a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for training, testing, and validation datasets.\n",
    "# Each DataLoader wraps the RNA and protein data using the SCDataset class,\n",
    "# and loads data in batches according to the specified batch size.\n",
    "# The training loader shuffles the data, while the test and validation loaders maintain order.\n",
    "train_loader = DataLoader(SCDataset(train_rna, train_protein), batch_size=args.batch_size, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(SCDataset(test_rna, test_protein), batch_size=args.test_batch_size, shuffle=False, drop_last=False)\n",
    "val_loader = DataLoader(SCDataset(val_rna, val_protein), batch_size=args.test_batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "# Set input and output dimensions\n",
    "# Configure the model's input and output dimensions based on the number of features in scRNA_adata and scP_adata.\n",
    "args.dim_rna = scRNA_adata.shape[1]\n",
    "args.dim_pro = scP_adata.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a761ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b66f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CosRep] Epoch 1, Train Loss: 1.7837, Val Loss: 0.5307, RMSE=0.4872, CCC=0.5342, pcc_cell=0.5583, pcc_pro=0.5794\n",
      "[CosRep] Epoch 2, Train Loss: 1.2931, Val Loss: 0.4360, RMSE=0.4421, CCC=0.6110, pcc_cell=0.5929, pcc_pro=0.6230\n",
      "[CosRep] Epoch 3, Train Loss: 1.1387, Val Loss: 0.4353, RMSE=0.4291, CCC=0.6440, pcc_cell=0.5901, pcc_pro=0.6329\n",
      "[CosRep] Epoch 4, Train Loss: 1.0222, Val Loss: 0.3946, RMSE=0.4379, CCC=0.6355, pcc_cell=0.5755, pcc_pro=0.6233\n",
      "[CosRep] Epoch 5, Train Loss: 0.9459, Val Loss: 0.4064, RMSE=0.4398, CCC=0.6460, pcc_cell=0.5656, pcc_pro=0.6339\n",
      "[CosRep] Epoch 6, Train Loss: 0.8755, Val Loss: 0.4080, RMSE=0.4318, CCC=0.6402, pcc_cell=0.5691, pcc_pro=0.6355\n",
      "[CosRep] Epoch 7, Train Loss: 0.8381, Val Loss: 0.3868, RMSE=0.4423, CCC=0.6466, pcc_cell=0.5659, pcc_pro=0.6367\n",
      "[CosRep] Epoch 8, Train Loss: 0.8209, Val Loss: 0.3898, RMSE=0.4438, CCC=0.6530, pcc_cell=0.5687, pcc_pro=0.6452\n",
      "[CosRep] Epoch 9, Train Loss: 1.0255, Val Loss: 0.3973, RMSE=0.4382, CCC=0.6367, pcc_cell=0.5587, pcc_pro=0.6364\n",
      "[CosRep] Epoch 10, Train Loss: 0.7774, Val Loss: 0.3796, RMSE=0.4395, CCC=0.6458, pcc_cell=0.5598, pcc_pro=0.6380\n",
      "[CosRep] Epoch 11, Train Loss: 0.7232, Val Loss: 0.3889, RMSE=0.4363, CCC=0.6525, pcc_cell=0.5657, pcc_pro=0.6447\n",
      "[CosRep] Epoch 12, Train Loss: 0.7040, Val Loss: 0.3903, RMSE=0.4399, CCC=0.6492, pcc_cell=0.5619, pcc_pro=0.6445\n",
      "[CosRep] Epoch 13, Train Loss: 0.6876, Val Loss: 0.3786, RMSE=0.4351, CCC=0.6567, pcc_cell=0.5638, pcc_pro=0.6467\n",
      "[CosRep] Epoch 14, Train Loss: 0.6651, Val Loss: 0.3938, RMSE=0.4395, CCC=0.6556, pcc_cell=0.5606, pcc_pro=0.6435\n",
      "[CosRep] Epoch 15, Train Loss: 0.6540, Val Loss: 0.3814, RMSE=0.4366, CCC=0.6562, pcc_cell=0.5603, pcc_pro=0.6465\n",
      "[CosRep] Epoch 16, Train Loss: 0.6385, Val Loss: 0.3671, RMSE=0.4411, CCC=0.6519, pcc_cell=0.5559, pcc_pro=0.6413\n",
      "[CosRep] Epoch 17, Train Loss: 0.6383, Val Loss: 0.3818, RMSE=0.4413, CCC=0.6451, pcc_cell=0.5537, pcc_pro=0.6378\n",
      "[CosRep] Epoch 18, Train Loss: 0.6566, Val Loss: 0.4026, RMSE=0.4447, CCC=0.6403, pcc_cell=0.5410, pcc_pro=0.6335\n",
      "Early stopping triggered at epoch 19\n"
     ]
    }
   ],
   "source": [
    "# Import the CoSRep model\n",
    "from model import CoSRep\n",
    "\n",
    "# Check if CUDA is available and set the device accordingly\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Initialize the model and move it to the selected device\n",
    "model = CoSRep(args).to(device)\n",
    "\n",
    "# Set up the Adam optimizer with the specified learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# Record the start time for training duration calculation\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize variables for tracking the best validation loss and early stopping\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "early_stop_patience = 3  # Number of epochs to wait before early stopping\n",
    "\n",
    "# Create directory for saving the best model\n",
    "os.makedirs('./best_model', exist_ok=True)\n",
    "\n",
    "# Extract dataset name from the RNA path for model saving\n",
    "dataset_name = args.RNA_path.strip('/').split('/')[1]\n",
    "best_model_path = f'./best_model/{dataset_name}_{args.method_flag}_{args.repeat}_best_model.pth'\n",
    "\n",
    "# Training loop over the specified number of epochs\n",
    "for epoch in range(args.epochs):\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Iterate over the training data loader\n",
    "    for rna, pro in train_loader:\n",
    "        # Move data to the selected device and convert to float\n",
    "        rna = rna.to(device).float()\n",
    "        pro = pro.to(device).float()\n",
    "        \n",
    "        # Forward pass: compute predictions and loss\n",
    "        pred, loss, _ = model(rna, pro)  # Use protein data as ground truth for loss calculation\n",
    "        \n",
    "        # Backward pass: compute gradients and update weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate the total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculate average training loss for the epoch\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # Save the current best model based on validation loss\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    all_val_preds, all_val_trues = [], []\n",
    "    val_loss = float('inf')\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    with torch.no_grad():\n",
    "        for rna, pro in val_loader:\n",
    "            # Move data to the selected device and convert to float\n",
    "            rna = rna.to(device).float()\n",
    "            pro = pro.to(device).float()\n",
    "            \n",
    "            # Forward pass: compute predictions and validation loss\n",
    "            pred, _, val_loss = model(rna, pro)\n",
    "            all_val_preds.append(pred.cpu())\n",
    "            all_val_trues.append(pro.cpu())\n",
    "    \n",
    "    # Concatenate predictions and ground truths for evaluation\n",
    "    pred_all = torch.cat(all_val_preds)\n",
    "    true_all = torch.cat(all_val_trues)\n",
    "    \n",
    "    # Update best model if validation loss improves\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        # Trigger early stopping if no improvement for specified patience\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "            break\n",
    "            \n",
    "    # ðŸ§ª Evaluate on the test set (do not modify)\n",
    "    model.eval()\n",
    "    all_preds, all_trues = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for rna, pro in test_loader:\n",
    "            # Move data to the selected device and convert to float\n",
    "            rna = rna.to(device).float()\n",
    "            \n",
    "            # Forward pass: compute predictions\n",
    "            pred, _, _, _ = model(rna)\n",
    "            all_preds.append(pred.cpu())\n",
    "            all_trues.append(pro.cpu())\n",
    "    \n",
    "    # Concatenate predictions and ground truths for final evaluation\n",
    "    pred_all = torch.cat(all_preds)\n",
    "    true_all = torch.cat(all_trues)\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    rmse, ccc, pcc_cell, pcc_pro = evaluate(pred_all, true_all)\n",
    "    \n",
    "    # Print epoch results\n",
    "    print(f'[CosRep] Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, RMSE={rmse:.4f}, CCC={ccc:.4f}, pcc_cell={pcc_cell:.4f}, pcc_pro={pcc_pro:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7010fa76",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1092f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CosRep] RMSE=0.4411, CCC=0.6519, pcc_cell=0.5559, pcc_pro=0.6413\n",
      "Training Time: 1.0m 46.54414081573486s\n"
     ]
    }
   ],
   "source": [
    "# Initialize variable to store predictions\n",
    "pred_all = None\n",
    "\n",
    "#  Test set evaluation\n",
    "#  Load the best model for final inference\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store predictions, ground truths, and latent representations\n",
    "all_preds, all_trues, all_fused_rna, all_shared_rna, all_specific_rna = [], [], [], [], []\n",
    "\n",
    "# Perform inference on the test set without gradient computation\n",
    "with torch.no_grad():\n",
    "    for rna, pro in test_loader:\n",
    "        # Move RNA data to the selected device and convert to float\n",
    "        rna = rna.to(device).float()\n",
    "        \n",
    "        # Forward pass: get predictions and latent representations\n",
    "        pred, z_fused_rna, z_shared_rna, z_specific_rna = model(rna)\n",
    "        \n",
    "        # Store predictions, ground truths, and latent representations\n",
    "        all_preds.append(pred.cpu())\n",
    "        all_trues.append(pro.cpu())\n",
    "        all_fused_rna.append(z_fused_rna.cpu())\n",
    "        all_shared_rna.append(z_shared_rna.cpu())\n",
    "        all_specific_rna.append(z_specific_rna.cpu())\n",
    "\n",
    "# Concatenate all predictions, ground truths, and latent representations\n",
    "pred_all = torch.cat(all_preds)\n",
    "true_all = torch.cat(all_trues)\n",
    "fused_rna_all = torch.cat(all_fused_rna)\n",
    "shared_rna_all = torch.cat(all_shared_rna)\n",
    "specific_rna_all = torch.cat(all_specific_rna)\n",
    "\n",
    "# Evaluate the model's performance using custom metrics\n",
    "rmse, ccc, pcc_cell, pcc_pro = evaluate(pred_all, true_all)\n",
    "\n",
    "# Print evaluation results\n",
    "print(f'[CosRep] RMSE={rmse:.4f}, CCC={ccc:.4f}, pcc_cell={pcc_cell:.4f}, pcc_pro={pcc_pro:.4f}')\n",
    "\n",
    "# Calculate and print the total training time\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'Training Time: {elapsed_time // 60}m {elapsed_time % 60}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
